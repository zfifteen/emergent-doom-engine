/bin/bash /Users/velocityworks/IdeaProjects/emergent-doom-engine/scripts/run_scaling_verification.sh

══════════════════════════════════════════════════════
  The Matrix has you...
══════════════════════════════════════════════════════

┌──[velocityworks@MacBookPro]─[~/IdeaProjects/emergent-doom-engine/scripts]
└──▶ $ /bin/bash /Users/velocityworks/IdeaProjects/emergent-doom-engine/scripts/run_scaling_verification.sh
=== Scaling Verification Experiment (Memory Optimized) ===
CSV: /Users/velocityworks/IdeaProjects/emergent-doom-engine/scripts/scaling_results.csv
=== Testing magnitude 1e4 (target=1022117) ===
  Array size n=50...
    → Steps: 34.35, Steps/n: .6870, Convergence: 100.0%
  Array size n=100...
    → Steps: 90.85, Steps/n: .9085, Convergence: 100.0%
  Array size n=200...
    → Steps: 193.05, Steps/n: .9652, Convergence: 100.0%
  Array size n=500...
    → Steps: 531.05, Steps/n: 1.0621, Convergence: 100.0%
  Array size n=1000...
    → Steps: 1104.65, Steps/n: 1.1046, Convergence: 100.0%
  Array size n=1500...
    → Steps: 1800.35, Steps/n: 1.2002, Convergence: 100.0%
  Array size n=2000...
    → Steps: 2435.85, Steps/n: 1.2179, Convergence: 100.0%
  Array size n=2500...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=3000...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=3500...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=4000...
^C
┌──[velocityworks@MacBookPro]─[~/IdeaProjects/emergent-doom-engine/scripts]
└──▶ $ /bin/bash /Users/velocityworks/IdeaProjects/emergent-doom-engine/scripts/run_scaling_verification.sh
=== Scaling Verification Experiment (Memory Optimized) ===
CSV: /Users/velocityworks/IdeaProjects/emergent-doom-engine/scripts/scaling_results.csv
=== Testing magnitude 1e4 (target=1022117) ===
  Array size n=50...
    → Steps: 34.50, Steps/n: .6900, Convergence: 100.0%
  Array size n=100...
    → Steps: 90.05, Steps/n: .9005, Convergence: 100.0%
  Array size n=200...
    → Steps: 189.45, Steps/n: .9472, Convergence: 100.0%
  Array size n=500...
    → Steps: 534.45, Steps/n: 1.0689, Convergence: 100.0%
  Array size n=1000...
    → Steps: 1095.10, Steps/n: 1.0951, Convergence: 100.0%
  Array size n=1500...
    → Steps: 1796.25, Steps/n: 1.1975, Convergence: 100.0%
  Array size n=2000...
    → Steps: 2428.20, Steps/n: 1.2141, Convergence: 100.0%
  Array size n=2500...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=3000...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=3500...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=4000...
    → Steps: 0, Steps/n: 0, Convergence: 0%
=== Testing magnitude 1e5 (target=100160063) ===
  Array size n=50...
    → Steps: 40.35, Steps/n: .8070, Convergence: 100.0%
  Array size n=100...
    → Steps: 93.95, Steps/n: .9395, Convergence: 100.0%
  Array size n=200...
    → Steps: 204.40, Steps/n: 1.0220, Convergence: 100.0%
  Array size n=500...
    → Steps: 560.75, Steps/n: 1.1215, Convergence: 100.0%
  Array size n=1000...
    → Steps: 1172.20, Steps/n: 1.1722, Convergence: 100.0%
  Array size n=1500...
    → Steps: 1848.60, Steps/n: 1.2324, Convergence: 100.0%
  Array size n=2000...
    → Steps: 2403.00, Steps/n: 1.2015, Convergence: 100.0%
  Array size n=2500...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=3000...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=3500...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=4000...
    → Steps: 0, Steps/n: 0, Convergence: 0%
=== Testing magnitude 1e6 (target=10002200057) ===
  Array size n=50...
    → Steps: 40.05, Steps/n: .8010, Convergence: 100.0%
  Array size n=100...
    → Steps: 90.35, Steps/n: .9035, Convergence: 100.0%
  Array size n=200...
    → Steps: 192.40, Steps/n: .9620, Convergence: 100.0%
  Array size n=500...
    → Steps: 579.05, Steps/n: 1.1581, Convergence: 100.0%
  Array size n=1000...
    → Steps: 1120.55, Steps/n: 1.1205, Convergence: 100.0%
  Array size n=1500...
    → Steps: 1842.20, Steps/n: 1.2281, Convergence: 100.0%
  Array size n=2000...
    → Steps: 2320.25, Steps/n: 1.1601, Convergence: 100.0%
  Array size n=2500...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=3000...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=3500...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=4000...
    → Steps: 0, Steps/n: 0, Convergence: 0%
=== Testing magnitude 1e9 (target=1000036000099) ===
  Array size n=50...
    → Steps: 35.60, Steps/n: .7120, Convergence: 100.0%
  Array size n=100...
    → Steps: 98.35, Steps/n: .9835, Convergence: 100.0%
  Array size n=200...
    → Steps: 208.40, Steps/n: 1.0420, Convergence: 100.0%
  Array size n=500...
    → Steps: 624.45, Steps/n: 1.2489, Convergence: 100.0%
  Array size n=1000...
    → Steps: 1137.70, Steps/n: 1.1377, Convergence: 100.0%
  Array size n=1500...
    → Steps: 1696.00, Steps/n: 1.1306, Convergence: 100.0%
  Array size n=2000...
    → Steps: 2446.65, Steps/n: 1.2233, Convergence: 100.0%
  Array size n=2500...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=3000...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=3500...
    → Steps: 0, Steps/n: 0, Convergence: 0%
  Array size n=4000...
    → Steps: 0, Steps/n: 0, Convergence: 0%
Generating analysis report...
Traceback (most recent call last):
  File "/Users/velocityworks/IdeaProjects/emergent-doom-engine/scripts/analyze_scaling.py", line 8, in <module>
    df = pd.read_csv(csv_file)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 626, in _read
    return parser.read(nrows)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1968, in read
    df = DataFrame(
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/frame.py", line 782, in __init__
    mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/internals/construction.py", line 443, in dict_to_mgr
    arrays = Series(data, index=columns, dtype=object)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/series.py", line 493, in __init__
    index = ensure_index(index)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 7713, in ensure_index
    return Index(index_like, copy=copy, tupleize_cols=False)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 566, in __new__
    arr = sanitize_array(data, None, dtype=dtype, copy=copy)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/construction.py", line 651, in sanitize_array
    subarr = maybe_convert_platform(data)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/dtypes/cast.py", line 138, in maybe_convert_platform
    arr = lib.maybe_convert_objects(arr)
  File "pandas/_libs/lib.pyx", line 2555, in pandas._libs.lib.maybe_convert_objects
TypeError: Cannot convert numpy.ndarray to numpy.ndarray
Analysis script failed.
Experiment complete!
┌──[velocityworks@MacBookPro]─[~/IdeaProjects/emergent-doom-engine/scripts]
└──▶ $

